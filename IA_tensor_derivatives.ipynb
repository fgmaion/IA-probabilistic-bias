{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349bee31",
   "metadata": {},
   "source": [
    "# Probabilistic Shape Biases\n",
    "\n",
    "### This Notebook is a complement to the paper\n",
    "\n",
    "#### **Probabilistic Estimators of Lagrangian Shape Biases: Universal Relations and Physical Insights** [(Maion, Stucker, Angulo, 2024)](https://arxiv.org/pdf/2409.14995)\n",
    "\n",
    "The calculations necessary to reach equations (29,30) and (42,43) of that paper can be quite cumbersome. Therefore, we have developed a semi-numerical approach to perform those calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341b3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import numpy as np\n",
    "import os\n",
    "from sympy import *\n",
    "\n",
    "os.chdir(\"/cosmos_storage/home/fgmaion/IA-probabilistic-bias\")\n",
    "\n",
    "import IA_isotropic_tensors as IA_it\n",
    "import isotropic_tensors as it\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403110e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IA_its = IA_it.IsotropicTensorSystem(usecache=True)\n",
    "D_its  = it.IsotropicTensorSystem(usecache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ec631",
   "metadata": {},
   "source": [
    "## Bias Estimators\n",
    "\n",
    "From equation (26) of Maion et. al (2024) we know that the probability distribution for the tidal-field is given by:\n",
    "$$\n",
    "p(\\mathbf{T}) = N \\exp\\left[-\\frac{1}{2}\\mathbf{T}\\mathbf{C}_T^\\dagger\\mathbf{T} \\right],\n",
    "$$\n",
    "where the pseudo-inverse covariance is obtained in Stucker et. al (2023), and shown to be\n",
    "$$\n",
    "\\mathbf{C}_T^\\dagger = \\frac{1}{\\sigma^2}\\mathbf{J}_{22} + \\frac{15}{2\\sigma^2}\\mathbf{J}_{2=2},\n",
    "$$\n",
    "in which $\\mathbf{J}$ are the orthogonal isotropic tensors described in these two papers; we also refer the reader to another notebook in this repository <code>tensor_algebra.ipynb</code>, where the algebraic properties of these tensors and their definitions are explored in more depth.\n",
    "\n",
    "The purpose of this Notebook is to use semi-numeric methods defined in <code>IA_isotropic_tensors.py</code> to explicitly compute the expressions for the bias estimators derived in Maion et al (2024):\n",
    "$$\n",
    "c_{J_{22}} = \\left\\langle \\mathbf{C}_T^\\dagger \\mathbf{T}\\otimes\\mathbf{I}\\overset{(4)}{\\cdot} \\frac{\\mathbf{J}_{22}}{||\\mathbf{J}_{22}||^2}_g \\right\\rangle\\\\\n",
    "c_{J_{2=2}} = \\left\\langle \\mathbf{C}_T^\\dagger \\mathbf{T}\\otimes\\mathbf{I}\\overset{(4)}{\\cdot} \\frac{\\mathbf{J}_{2=2}}{||\\mathbf{J}_{2=2}||^2}_g \\right\\rangle\n",
    "$$\n",
    "and\n",
    "$$\n",
    "c_{J_{2=22}} = \\left\\langle \\frac{1}{p(\\mathbf{T})} \\left( p\\frac{\\partial F}{\\partial \\mathbf{T}}\\frac{\\partial F}{\\partial \\mathbf{T}}-p \\frac{\\partial^2 F}{\\partial \\mathbf{T}^2} + 2 \\frac{\\partial p}{\\partial \\mathbf{T}} \\frac{\\partial F}{\\partial \\mathbf{T}} + \\frac{\\partial^2 p}{\\partial \\mathbf{T}^2} \\right) \\otimes \\mathbf{I} \\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2}  \\right\\rangle_{\\mathrm{g}}\\\\\n",
    "c_{J_{2-2-2-}} = \\left\\langle \\frac{1}{p(\\mathbf{T})} \\left( p\\frac{\\partial F}{\\partial \\mathbf{T}}\\frac{\\partial F}{\\partial \\mathbf{T}}-p \\frac{\\partial^2 F}{\\partial \\mathbf{T}^2} + 2 \\frac{\\partial p}{\\partial \\mathbf{T}} \\frac{\\partial F}{\\partial \\mathbf{T}} + \\frac{\\partial^2 p}{\\partial \\mathbf{T}^2} \\right) \\otimes \\mathbf{I} \\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2-2-2-}}{||\\mathbf{J}_{2-2-2-}||^2}  \\right\\rangle_{\\mathrm{g}}.\n",
    "$$\n",
    "\n",
    "Let us start with the first two, which are a bit simpler, and then pass to the next two.\n",
    "\n",
    "## $c_{J_{22}}, c_{J_{2=2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d47e5",
   "metadata": {},
   "source": [
    "The first step is to represent the pseudo-inverse covariance in semi-numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24108d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260344/2799662498.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  symbol_res = np.sum( basis[key].symbol() * Ci_coeffrep[0][0][0][i] for i, key in enumerate(keys)  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{J_{22}}{\\sigma_{0}^{2}} + \\frac{15 J_{2=2}}{2 \\sigma_{0}^{2}}$"
      ],
      "text/plain": [
       "J_22/sigma0**2 + 15*J_2=2/(2*sigma0**2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potderiv = (2,)\n",
    "\n",
    "Ci, sigma, As, Js = IA_its.pseudo_inverse_covariance_matrix(potderiv, full_output=True)\n",
    "\n",
    "nderiv = len(potderiv)\n",
    "\n",
    "#coefficients that can be combined to basis tensors to get full expression of C_dagger\n",
    "Ci_coeffrep = []\n",
    "for i in range(0,nderiv):\n",
    "    Ci_coeffrep.append([])\n",
    "    for j in range(0,nderiv):\n",
    "        Ci_coeffrep[i].append((As[i][j], (potderiv[i], potderiv[j])))\n",
    "\n",
    "#fully numerical version of pseudo-inverse covariance\n",
    "C_dag = As[0][0][0]*IA_its.obasis[\"22\"][\"J22\"].N() + As[0][0][1]*IA_its.obasis[\"22\"][\"J2=2\"].N()\n",
    "\n",
    "#print symbolic expression of this matrix\n",
    "basis = IA_its.obasis['22']\n",
    "keys = list(basis.keys())\n",
    "symbol_res = np.sum( basis[key].symbol() * Ci_coeffrep[0][0][0][i] for i, key in enumerate(keys)  )\n",
    "symbol_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59375589",
   "metadata": {},
   "source": [
    "and the next step is to use functions of the code to perform the relevant tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d48e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{3 J_{2=2} T I}{2 \\sigma_{0}^{2}}$"
      ],
      "text/plain": [
       "3*J_2=2*T*I/(2*sigma0**2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = 0\n",
    "I = IA_its.I[0]\n",
    "\n",
    "for i in range(0, nderiv):\n",
    "    crep = IA_its.coeffrep_multidot(IA_its.obasis[\"22\"][\"J2=2\"], Ci_coeffrep[0][i], products=(1,))\n",
    "\n",
    "    res += IA_its.coeffrep_to_symbol(*crep) * IA_its.x[i] * I / IA_its.obasis[\"22\"][\"J2=2\"].norm2()\n",
    "\n",
    "sympy.together(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffcf5f",
   "metadata": {},
   "source": [
    "There is also a pre-defined function that incorporates these steps into one single function call. The parameters that have to be provided are simply to term to be computed, and up to which order in the derivatives of the potential you wish to go (so far this is only implemented for the case <code>potderiv=(2,)</code> )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004304e",
   "metadata": {},
   "source": [
    "### $c_{J_{22}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "490c1d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{J_{22} T I}{3 \\sigma_{0}^{2}}$"
      ],
      "text/plain": [
       "J_22*T*I/(3*sigma0**2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_its.IA_symbol_bias_deriv1(term=\"J22\", potderiv=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237b2a52",
   "metadata": {},
   "source": [
    "### $c_{J_{2=2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "221b8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{3 J_{2=2} T I}{2 \\sigma_{0}^{2}}$"
      ],
      "text/plain": [
       "3*J_2=2*T*I/(2*sigma0**2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_its.IA_symbol_bias_deriv1(term=\"J2=2\", potderiv=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650521c6",
   "metadata": {},
   "source": [
    "## Now let's move to the calculation of the estimators for the higher-order parameters\n",
    "\n",
    "For that we need the second-derivative of the probability distribution\n",
    "$$\n",
    "\\frac{1}{p}\\frac{\\partial^2 p}{\\partial \\mathbf{T}^2} = \\frac{1}{4}\\left[ \\mathbf{C}_T^\\dagger(\\mathbf{T}+\\mathbf{T}^T) \\right] \\otimes \\left[ \\mathbf{C}_T^\\dagger(\\mathbf{T}+\\mathbf{T}^T)\\right] - \\mathbf{C}_T^\\dagger,\n",
    "$$\n",
    "and we will need the derivatives of $F$, the large-scale bias function, evaluated at $\\mathbf{T}=0$\n",
    "$$\n",
    "\\frac{\\partial F}{\\partial \\mathbf{T}}(0) = \\mathbf{B}_{T,1}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial^2 F}{\\partial \\mathbf{T}^2}(0) = \\mathbf{B}_{T,2},\n",
    "$$\n",
    "in which $\\mathbf{B}_{T,1}$ and $\\mathbf{B}_{T,2}$ are the first and second-order generalized density-bias tensors\n",
    "$$\n",
    "\\mathbf{B}_{T,1} = b_1\\mathbf{J}_{2}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{B}_{T,2} = b_2\\mathbf{J}_{22} + 2b_{K^2}\\mathbf{J}_{2=2}.\n",
    "$$\n",
    "\n",
    "Let us start with the contributions that come from the second derivatives of the probability distribution, as those will be the main ones. All we need to do then is to contract this second derivative with the relevant tensor, and normalize it by its amplitude.\n",
    "\n",
    "## $c_{J_{2-2-2-}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "788a0be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{135 J_{2-2-2-} T^{2} I}{7 \\sigma_{0}^{4}}$"
      ],
      "text/plain": [
       "135*J_2-2-2-*T**2*I/(7*sigma0**4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=0\n",
    "#norm of the relevant tensor\n",
    "norm2 = sympy.Rational(IA_its.obasis[\"222\"][\"J2-2-2-\"].norm2()).limit_denominator(10**8)\n",
    "\n",
    "for i in range(0, nderiv):\n",
    "    for j in range(0, nderiv):\n",
    "        #2-dimensional dot product of pseudo-inverse covariance matrices with basis tensor\n",
    "        crep = IA_its.coeffrep_multidot(IA_its.obasis[\"222\"][\"J2-2-2-\"], Ci_coeffrep[0][i], Ci_coeffrep[0][j], products=(1,1))\n",
    "        #outer product of the result to the two instances of the tidal fiend and the moment of inertia, I\n",
    "        res += IA_its.coeffrep_to_symbol(*crep) * IA_its.x[i] * IA_its.x[j] * IA_its.I[0] / norm2\n",
    "\n",
    "# two-dimensional dot product of pseudo-inverse covariance matrices with basis tensor\n",
    "crep = IA_its.coeffrep_multidot(IA_its.obasis[\"222\"][\"J2-2-2-\"], Ci_coeffrep[0][0], products=(2,))\n",
    "#\n",
    "res += - IA_its.coeffrep_to_symbol(*crep) * IA_its.I[0] / norm2\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a ready function to do that for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb500b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{135 J_{2-2-2-} T^{2} I}{7 \\sigma_{0}^{4}}$"
      ],
      "text/plain": [
       "135*J_2-2-2-*T**2*I/(7*sigma0**4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_its.IA_symbol_bias_deriv2(term=\"J2-2-2-\", potderiv=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297012d4",
   "metadata": {},
   "source": [
    "## $c_{J_{22=2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034082db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{3 J_{222=} T^{2} I}{2 \\sigma_{0}^{4}}$"
      ],
      "text/plain": [
       "3*J_222=*T**2*I/(2*sigma0**4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_its.IA_symbol_bias_deriv2(term=\"J22=2\", potderiv=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff67e4",
   "metadata": {},
   "source": [
    "### Now we need to go back and compute the contributions from the derivatives of the number-density bias function\n",
    "\n",
    "I will demonstrate how to perform this calculation for $c_{J2=22}$, since that one receives a non-zero calculation. The same is completely analogous for $c_{J_{2-2-2-}}$\n",
    "\n",
    "Remembering the expression for this coefficient, we have\n",
    "$$\n",
    "c_{J_{2=22}} = \\left\\langle \\frac{1}{p(\\mathbf{T})} \\left( p\\frac{\\partial F}{\\partial \\mathbf{T}}\\frac{\\partial F}{\\partial \\mathbf{T}}-p \\frac{\\partial^2 F}{\\partial \\mathbf{T}^2} + 2 \\frac{\\partial p}{\\partial \\mathbf{T}} \\frac{\\partial F}{\\partial \\mathbf{T}} + \\frac{\\partial^2 p}{\\partial \\mathbf{T}^2} \\right) \\otimes \\mathbf{I} \\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2}  \\right\\rangle_{\\mathrm{g}}\\\\\n",
    "$$\n",
    "so we need to compute\n",
    "$$\n",
    "\\frac{\\partial^2 F}{\\partial \\mathbf{T}^2}(0) \\otimes \\mathbf{I}\\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2} = \\mathbf{B}_{T,2} \\otimes \\mathbf{I}\\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2}\\\\ \n",
    "$$\n",
    "and\n",
    "$$\n",
    "2 \\frac{\\partial p}{\\partial \\mathbf{T}}\\otimes\\frac{\\partial F}{\\partial \\mathbf{T}}(0) \\otimes \\mathbf{I}\\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2} = -2\\mathbf{C}_T^\\dagger \\mathbf{T} \\otimes \\mathbf{B}_{T,1} \\otimes \\mathbf{I}\\overset{(6)}{\\cdot}\\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2}\\\\\n",
    "$$\n",
    "\n",
    "It is not necesary to compute the contribution of\n",
    "$$\n",
    "\\frac{\\partial F}{\\partial \\mathbf{T}}(0)\\frac{\\partial F}{\\partial \\mathbf{T}}(0)\\otimes \\mathbf{I} \\overset{(6)}{\\cdot} \\frac{\\mathbf{J}_{2=22}}{||\\mathbf{J}_{2=22}||^2}\n",
    "$$\n",
    "since this will clearly not have a trace-free contribution, and will return a null contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b726a0",
   "metadata": {},
   "source": [
    "### Define the density bias tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f07ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1, b2, b3, bK2, bdk, bkk = sympy.symbols('b1 b2 b3 bK2 bdk bkk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb2a5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized bias tensors\n",
    "B_1 = b1*D_its.obasis['2']['J2'].N()\n",
    "B_2 = b2*D_its.obasis['22']['J22'].N() + 2*bK2*D_its.obasis['22']['J2=2'].N()\n",
    "B_3 = b3*D_its.obasis['222']['J222'].N() + bdk*D_its.obasis['222']['J2=22'].N() + bkk*D_its.obasis['222']['J2-2-2-'].N()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e645035",
   "metadata": {},
   "source": [
    "$\\mathbf{J}_{2=22} \\overset{(4)}{\\cdot} \\left( \\mathbf{C}_T^\\dagger \\otimes \\mathbf{B}_1 \\right) = $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a0e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_260344/1695721579.py:4: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  symbol_res = np.sum( basis[key].symbol() * res[i] for i, key in enumerate(keys)  )\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{45 b_{1} J_{2=2}}{2 \\sigma_{0}^{2}}$"
      ],
      "text/plain": [
       "45*b1*J_2=2/(2*sigma0**2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = IA_its.decompose(np.einsum('abijmn,ijkl,mn', IA_its.obasis[\"222\"][\"J2=22\"].N(), C_dag, B_1, optimize='optimal'), \"22\")\n",
    "basis = IA_its.obasis['22']\n",
    "keys = list(basis.keys())\n",
    "symbol_res = np.sum( basis[key].symbol() * res[i] for i, key in enumerate(keys)  )\n",
    "symbol_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "170f3592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_its.obasis[\"222\"][\"J2=22\"].norm2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104a6b9",
   "metadata": {},
   "source": [
    "and these results should now be plugged into the equation above, performing the additional 4-dimensional dot product with $\\mathbf{T}$ and $\\mathbf{I}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5024528",
   "metadata": {},
   "source": [
    "$-2\\frac{1}{|J_{2=22}|^2}\\frac{45 b_{1} J_{2=2}}{2 \\sigma_{0}^{2}} I T = -2b_1\\frac{3}{2\\sigma_0^2}\\mathrm{Tr}(KI) = -2b_1c_K $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
